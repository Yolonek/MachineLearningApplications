from tqdm import tqdm
from matplotlib import pyplot as plt
from CommonFunctions import enhance_plot
import torch
import numpy as np


def autoencoder_train_loop(model, dataloader, criterion,
                           optimizer, device, epochs):
    loss_list = []
    model.train()
    with tqdm(range(epochs)) as pbar:
        for _ in pbar:
            loss_train = 0
            for images, _ in dataloader:
                images = images.to(device)
                outputs = model(images)
                loss = criterion(outputs, images)
                loss_train += (loss_value := loss.item())
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                pbar.set_postfix(loss=loss_value)
            loss_list.append(loss_train / len(dataloader))
    return loss_list


def plot_loss(figure, axes, epochs, loss_dict, config_dict, colors):
    with plt.style.context('cyberpunk'):
        x_axis = range(1, epochs + 1)
        for (loss_type, loss), color in zip(loss_dict.items(), colors):
            axes.plot(x_axis, loss, label=f'{loss_type}: {min(loss):.3f}', color=color)
        axes.set(**config_dict)
        axes.legend()
        enhance_plot(figure, axes, glow=True)


def sample_random_digits(mnist_dataset, seed=42):
    torch.manual_seed(seed)
    targets = mnist_dataset.targets.numpy()
    samples = {}
    for digit in range(10):
        indices = [i for i, label in enumerate(targets) if label == digit]
        chosen_idx = np.random.choice(indices)
        samples[digit] = mnist_dataset[chosen_idx][0]
    return samples


def compare_generated_to_original_mnist(model, mnist_dataset):
    model.eval()
    figure, axes = plt.subplots(2, 10, figsize=(15, 3))
    image_dict = sample_random_digits(mnist_dataset, seed=42)
    for digit, img in image_dict.items():
        axes[0][digit].imshow(img.permute(1, 2, 0).numpy(), cmap='Greys')
        reconstruction = model.cpu()(img.unsqueeze(0)).squeeze(0)
        axes[1][digit].imshow(reconstruction.detach().permute(1, 2, 0).numpy(), cmap='Greys')
    for ax in axes.ravel():
        ax.axis(False)
    figure.text(0.5, 0.93, 'Original Images', ha='center', va='center', fontsize=14)
    figure.text(0.5, 0.48, 'Generated by Autoencoder', ha='center', va='center', fontsize=14)

