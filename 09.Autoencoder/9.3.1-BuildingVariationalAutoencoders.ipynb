{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dense Variational Autoencoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3be0af905bccde6b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from functools import reduce\n",
    "import operator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.614330200Z",
     "start_time": "2025-03-10T16:53:43.742914800Z"
    }
   },
   "id": "804347b0365e2256",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from ModelClasses.Autoencoders import DenseBlock, DenseDecoder, ConvolutionalBlock, ConvolutionalDecoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.625330200Z",
     "start_time": "2025-03-10T16:53:45.615834Z"
    }
   },
   "id": "5f88bd17710bab53",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.635336600Z",
     "start_time": "2025-03-10T16:53:45.626833500Z"
    }
   },
   "id": "d31c2881f51754ac",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DenseVariationalEncoder(DenseBlock):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_shape: tuple[int:],\n",
    "                 hidden_layers: tuple[int:] = None,\n",
    "                 latent_space_dimension: int = 2,\n",
    "                 dropout: float = 0.2):\n",
    "        self.input_shape = input_shape\n",
    "        input_size = reduce(operator.mul, input_shape)\n",
    "        super(DenseVariationalEncoder, self).__init__(\n",
    "            input_size=input_size,\n",
    "            hidden_layers=hidden_layers,\n",
    "            dropout=dropout)\n",
    "        self.latent_space_dim = latent_space_dimension\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_mu, self.dense_logvar = self._build_variational_layer()\n",
    "    \n",
    "    def _build_variational_layer(self):\n",
    "        if self.num_of_layers == 0:\n",
    "            in_features = self.input_size\n",
    "        else:\n",
    "            in_features = self.hidden_layers[-1]\n",
    "        mu_layer = nn.Linear(in_features=in_features,\n",
    "                             out_features=self.latent_space_dim)\n",
    "        logvar_layer = nn.Linear(in_features=in_features,\n",
    "                                 out_features=self.latent_space_dim)\n",
    "        return mu_layer, logvar_layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense_layers(self.flatten(x))\n",
    "        return self.dense_mu(x), self.dense_logvar(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.638331400Z",
     "start_time": "2025-03-10T16:53:45.635849400Z"
    }
   },
   "id": "e284fcd02144d82f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseVariationalEncoder(\n",
      "  (dense_layers): Sequential(\n",
      "    (dense_layer1): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (dense_layer2): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense_mu): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dense_logvar): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = [1, 28, 28]\n",
    "hidden_layers = [256, 128]\n",
    "latent_space_dim = 2\n",
    "\n",
    "encoder = DenseVariationalEncoder(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    hidden_layers=hidden_layers,\n",
    "    latent_space_dimension=latent_space_dim\n",
    ")\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.652829200Z",
     "start_time": "2025-03-10T16:53:45.641334800Z"
    }
   },
   "id": "698d415de79bd92b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 256]         200,960\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "         LayerNorm-4                  [-1, 256]             512\n",
      "           Dropout-5                  [-1, 256]               0\n",
      "            Linear-6                  [-1, 128]          32,896\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "         LayerNorm-8                  [-1, 128]             256\n",
      "           Dropout-9                  [-1, 128]               0\n",
      "           Linear-10                    [-1, 2]             258\n",
      "           Linear-11                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 235,140\n",
      "Trainable params: 235,140\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.90\n",
      "Estimated Total Size (MB): 0.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(encoder, input_size=tuple(INPUT_SHAPE), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.665830900Z",
     "start_time": "2025-03-10T16:53:45.646833500Z"
    }
   },
   "id": "d194929a8b66a4e7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1363, -0.0058],\n",
      "        [ 0.0648, -0.6677],\n",
      "        [ 0.6452,  0.2945]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1427,  1.1920],\n",
      "        [-1.5359,  0.3155],\n",
      "        [ 0.1362, -0.0895]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.randn(3, *INPUT_SHAPE)\n",
    "encoder_mu, encoder_logvar = encoder(test_tensor)\n",
    "print(encoder_mu)\n",
    "print(encoder_logvar)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.711330700Z",
     "start_time": "2025-03-10T16:53:45.658332100Z"
    }
   },
   "id": "c000c4b9035573c0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DenseVariationalAutoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_shape: tuple[int:],\n",
    "                 encoder_hidden_layers: tuple[int:] = None,\n",
    "                 decoder_hidden_layers: tuple[int:] = None,\n",
    "                 latent_space_dimension: int = 2,\n",
    "                 dropout: float = 0.1):\n",
    "        super(DenseVariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = DenseVariationalEncoder(\n",
    "            input_shape=input_shape,\n",
    "            hidden_layers=encoder_hidden_layers,\n",
    "            latent_space_dimension=latent_space_dimension,\n",
    "            dropout=dropout)\n",
    "\n",
    "        if decoder_hidden_layers is None:\n",
    "            decoder_hidden_layers = self.encoder.hidden_layers[::-1]\n",
    "        self.decoder = DenseDecoder(\n",
    "            output_shape=input_shape,\n",
    "            hidden_layers=decoder_hidden_layers,\n",
    "            latent_space_dimension=latent_space_dimension,\n",
    "            dropout=dropout)\n",
    "    \n",
    "    @staticmethod    \n",
    "    def reparametrization(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "    \n",
    "    def encode_and_reparametrize(self, x):\n",
    "        return self.reparametrization(*self.encoder(x))\n",
    "    \n",
    "    def forward_mu_logvar(self, mu, logvar):\n",
    "        z = self.reparametrization(mu, logvar)\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return self.forward_mu_logvar(mu, logvar), mu, logvar\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.715830900Z",
     "start_time": "2025-03-10T16:53:45.668332500Z"
    }
   },
   "id": "e5075f4b9a18b414",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseVariationalAutoencoder(\n",
      "  (encoder): DenseVariationalEncoder(\n",
      "    (dense_layers): Sequential(\n",
      "      (dense_layer1): Sequential(\n",
      "        (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (dense_layer2): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (dense_mu): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (dense_logvar): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): DenseDecoder(\n",
      "    (dense_layers): Sequential(\n",
      "      (dense_layer1): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (dense_layer2): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (output_layer): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=784, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = DenseVariationalAutoencoder(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    encoder_hidden_layers=hidden_layers,\n",
    "    latent_space_dimension=latent_space_dim\n",
    ")\n",
    "vae.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.732833600Z",
     "start_time": "2025-03-10T16:53:45.672834Z"
    }
   },
   "id": "feebf87105c28aef",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 256]         200,960\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "         LayerNorm-4                  [-1, 256]             512\n",
      "           Dropout-5                  [-1, 256]               0\n",
      "            Linear-6                  [-1, 128]          32,896\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "         LayerNorm-8                  [-1, 128]             256\n",
      "           Dropout-9                  [-1, 128]               0\n",
      "           Linear-10                    [-1, 2]             258\n",
      "           Linear-11                    [-1, 2]             258\n",
      "DenseVariationalEncoder-12         [[-1, 2], [-1, 2]]               0\n",
      "           Linear-13                  [-1, 128]             384\n",
      "             ReLU-14                  [-1, 128]               0\n",
      "        LayerNorm-15                  [-1, 128]             256\n",
      "          Dropout-16                  [-1, 128]               0\n",
      "           Linear-17                  [-1, 256]          33,024\n",
      "             ReLU-18                  [-1, 256]               0\n",
      "        LayerNorm-19                  [-1, 256]             512\n",
      "          Dropout-20                  [-1, 256]               0\n",
      "           Linear-21                  [-1, 784]         201,488\n",
      "          Sigmoid-22                  [-1, 784]               0\n",
      "     DenseDecoder-23            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 470,804\n",
      "Trainable params: 470,804\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 1.80\n",
      "Estimated Total Size (MB): 1.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, input_size=tuple(INPUT_SHAPE), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.772329800Z",
     "start_time": "2025-03-10T16:53:45.681331700Z"
    }
   },
   "id": "1ebd861da211cf5f",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1, 28, 28])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output = vae.forward_mu_logvar(encoder_mu, encoder_logvar)\n",
    "decoder_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.808831600Z",
     "start_time": "2025-03-10T16:53:45.690331900Z"
    }
   },
   "id": "4f938fd9332ca0aa",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1, 28, 28])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output, _, _ = vae(test_tensor)\n",
    "decoder_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.810332Z",
     "start_time": "2025-03-10T16:53:45.697333400Z"
    }
   },
   "id": "471d225ce1ccf693",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Variational Autoencoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad93b23285db3ab3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ConvolutionalVariationalEncoder(ConvolutionalBlock):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_shape: tuple[int, int, int],\n",
    "                 convolutional_filters: tuple[int:],\n",
    "                 convolutional_kernels: tuple[int:],\n",
    "                 convolutional_strides: tuple[int:],\n",
    "                 latent_space_dimension: int = 2):\n",
    "        super(ConvolutionalVariationalEncoder, self).__init__(\n",
    "            input_shape=input_shape,\n",
    "            convolutional_filters=convolutional_filters,\n",
    "            convolutional_kernels=convolutional_kernels,\n",
    "            convolutional_strides=convolutional_strides\n",
    "        )\n",
    "        self.latent_space_dim = latent_space_dimension\n",
    "        self.shape_before_bottleneck = None\n",
    "        self.shape_flattened = None\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_mu, self.dense_logvar = self._build_variational_layer()\n",
    "    \n",
    "    def _build_variational_layer(self):\n",
    "        dummy_input = torch.zeros(1, *self.input_shape)\n",
    "        conv_out = self.conv_layers(dummy_input)\n",
    "        self.shape_before_bottleneck = conv_out.shape[1:]\n",
    "        self.shape_flattened = conv_out.numel()\n",
    "        mu_layer = nn.Linear(in_features=self.shape_flattened,\n",
    "                             out_features=self.latent_space_dim)\n",
    "        logvar_layer = nn.Linear(in_features=self.shape_flattened,\n",
    "                                 out_features=self.latent_space_dim)\n",
    "        return mu_layer, logvar_layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(self.conv_layers(x))\n",
    "        return self.dense_mu(x), self.dense_logvar(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.811830900Z",
     "start_time": "2025-03-10T16:53:45.702834600Z"
    }
   },
   "id": "aeb2990c8aa19883",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalVariationalEncoder(\n",
      "  (conv_layers): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense_mu): Linear(in_features=3136, out_features=2, bias=True)\n",
      "  (dense_logvar): Linear(in_features=3136, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = [1, 28, 28]\n",
    "conv_filters = [32, 64, 64, 64]\n",
    "conv_kernels = [3, 3, 3, 3]\n",
    "conv_strides = [1, 2, 2, 1]\n",
    "latent_space_dim = 2\n",
    "\n",
    "encoder = ConvolutionalVariationalEncoder(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    convolutional_filters=conv_filters,\n",
    "    convolutional_kernels=conv_kernels,\n",
    "    convolutional_strides=conv_strides,\n",
    "    latent_space_dimension=latent_space_dim\n",
    ")\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.827330400Z",
     "start_time": "2025-03-10T16:53:45.713330200Z"
    }
   },
   "id": "50414ff4e8a7b5ab",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "       BatchNorm2d-3           [-1, 32, 28, 28]              64\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
      "              ReLU-5           [-1, 64, 14, 14]               0\n",
      "       BatchNorm2d-6           [-1, 64, 14, 14]             128\n",
      "            Conv2d-7             [-1, 64, 7, 7]          36,928\n",
      "              ReLU-8             [-1, 64, 7, 7]               0\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "           Conv2d-10             [-1, 64, 7, 7]          36,928\n",
      "             ReLU-11             [-1, 64, 7, 7]               0\n",
      "      BatchNorm2d-12             [-1, 64, 7, 7]             128\n",
      "          Flatten-13                 [-1, 3136]               0\n",
      "           Linear-14                    [-1, 2]           6,274\n",
      "           Linear-15                    [-1, 2]           6,274\n",
      "================================================================\n",
      "Total params: 105,668\n",
      "Trainable params: 105,668\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.03\n",
      "Params size (MB): 0.40\n",
      "Estimated Total Size (MB): 1.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(encoder, input_size=tuple(INPUT_SHAPE), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.829330Z",
     "start_time": "2025-03-10T16:53:45.724833Z"
    }
   },
   "id": "edd009c90a17b5d0",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0319,  0.0096],\n",
      "        [-0.3022, -0.6049],\n",
      "        [ 0.8684, -0.1028]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2856, -0.5393],\n",
      "        [ 1.2359, -1.1103],\n",
      "        [ 0.4542, -0.0900]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoder_mu, encoder_logvar = encoder(test_tensor)\n",
    "print(encoder_mu)\n",
    "print(encoder_logvar)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.841831100Z",
     "start_time": "2025-03-10T16:53:45.735331500Z"
    }
   },
   "id": "c220a67d591ca7de",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ConvolutionalVariationalAutoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_shape: tuple[int, int, int],\n",
    "                 convolutional_filters: tuple[int:],\n",
    "                 convolutional_kernels: tuple[int:],\n",
    "                 convolutional_strides: tuple[int:],\n",
    "                 latent_space_dimension: int = 2,\n",
    "                 convolutional_transpose_filters: tuple[int:] = None,\n",
    "                 convolutional_transpose_kernels: tuple[int:] = None,\n",
    "                 convolutional_transpose_strides: tuple[int:] = None):\n",
    "        super(ConvolutionalVariationalAutoencoder, self).__init__()\n",
    "\n",
    "        if convolutional_transpose_filters is None:\n",
    "            convolutional_transpose_filters = convolutional_filters[::-1]\n",
    "        if convolutional_transpose_kernels is None:\n",
    "            convolutional_transpose_kernels = convolutional_kernels[::-1]\n",
    "        if convolutional_transpose_strides is None:\n",
    "            convolutional_transpose_strides = convolutional_strides[::-1]\n",
    "\n",
    "        self.encoder = ConvolutionalVariationalEncoder(\n",
    "            input_shape=input_shape,\n",
    "            convolutional_filters=convolutional_filters,\n",
    "            convolutional_kernels=convolutional_kernels,\n",
    "            convolutional_strides=convolutional_strides,\n",
    "            latent_space_dimension=latent_space_dimension\n",
    "        )\n",
    "        self.decoder = ConvolutionalDecoder(\n",
    "            latent_space_dimension=latent_space_dimension,\n",
    "            shape_before_bottleneck=self.encoder.shape_before_bottleneck,\n",
    "            convolutional_transpose_filters=convolutional_transpose_filters,\n",
    "            convolutional_transpose_kernels=convolutional_transpose_kernels,\n",
    "            convolutional_transpose_strides=convolutional_transpose_strides,\n",
    "            out_channels=input_shape[0]\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def reparametrization(mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "\n",
    "    def encode_and_reparametrize(self, x):\n",
    "        return self.reparametrization(*self.encoder(x))\n",
    "\n",
    "    def forward_mu_logvar(self, mu, logvar):\n",
    "        z = self.reparametrization(mu, logvar)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        return self.forward_mu_logvar(mu, logvar), mu, logvar\n",
    "\n",
    "    def summary(self):\n",
    "        print(self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.843330900Z",
     "start_time": "2025-03-10T16:53:45.747832700Z"
    }
   },
   "id": "3098f5332e3baf8f",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalVariationalAutoencoder(\n",
      "  (encoder): ConvolutionalVariationalEncoder(\n",
      "    (conv_layers): Sequential(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (dense_mu): Linear(in_features=3136, out_features=2, bias=True)\n",
      "    (dense_logvar): Linear(in_features=3136, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder(\n",
      "    (convT_layers): Sequential(\n",
      "      (convTranspose1): Sequential(\n",
      "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (convTranspose2): Sequential(\n",
      "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (convTranspose3): Sequential(\n",
      "        (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (convTranspose4): Sequential(\n",
      "        (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (dense_layer): Linear(in_features=2, out_features=3136, bias=True)\n",
      "    (output_layer): Sequential(\n",
      "      (0): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = ConvolutionalVariationalAutoencoder(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    convolutional_filters=conv_filters,\n",
    "    convolutional_kernels=conv_kernels,\n",
    "    convolutional_strides=conv_strides,\n",
    "    latent_space_dimension=latent_space_dim\n",
    ")\n",
    "vae.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.881830600Z",
     "start_time": "2025-03-10T16:53:45.753332900Z"
    }
   },
   "id": "b08839ccdd646a84",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "       BatchNorm2d-3           [-1, 32, 28, 28]              64\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
      "              ReLU-5           [-1, 64, 14, 14]               0\n",
      "       BatchNorm2d-6           [-1, 64, 14, 14]             128\n",
      "            Conv2d-7             [-1, 64, 7, 7]          36,928\n",
      "              ReLU-8             [-1, 64, 7, 7]               0\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "           Conv2d-10             [-1, 64, 7, 7]          36,928\n",
      "             ReLU-11             [-1, 64, 7, 7]               0\n",
      "      BatchNorm2d-12             [-1, 64, 7, 7]             128\n",
      "          Flatten-13                 [-1, 3136]               0\n",
      "           Linear-14                    [-1, 2]           6,274\n",
      "           Linear-15                    [-1, 2]           6,274\n",
      "ConvolutionalVariationalEncoder-16         [[-1, 2], [-1, 2]]               0\n",
      "           Linear-17                 [-1, 3136]           9,408\n",
      "  ConvTranspose2d-18             [-1, 64, 7, 7]          36,928\n",
      "             ReLU-19             [-1, 64, 7, 7]               0\n",
      "      BatchNorm2d-20             [-1, 64, 7, 7]             128\n",
      "  ConvTranspose2d-21           [-1, 64, 14, 14]          36,928\n",
      "             ReLU-22           [-1, 64, 14, 14]               0\n",
      "      BatchNorm2d-23           [-1, 64, 14, 14]             128\n",
      "  ConvTranspose2d-24           [-1, 64, 28, 28]          36,928\n",
      "             ReLU-25           [-1, 64, 28, 28]               0\n",
      "      BatchNorm2d-26           [-1, 64, 28, 28]             128\n",
      "  ConvTranspose2d-27           [-1, 32, 28, 28]          18,464\n",
      "             ReLU-28           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "  ConvTranspose2d-30            [-1, 1, 28, 28]             289\n",
      "          Sigmoid-31            [-1, 1, 28, 28]               0\n",
      "ConvolutionalDecoder-32            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 245,061\n",
      "Trainable params: 245,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.15\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 4.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, input_size=tuple(INPUT_SHAPE), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.884830300Z",
     "start_time": "2025-03-10T16:53:45.764331800Z"
    }
   },
   "id": "f5289ac3e39eeabc",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1, 28, 28])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output = vae.forward_mu_logvar(encoder_mu, encoder_logvar)\n",
    "decoder_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.890329600Z",
     "start_time": "2025-03-10T16:53:45.791831Z"
    }
   },
   "id": "b4b2655c322627a7",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1, 28, 28])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output, _, _ = vae(test_tensor)\n",
    "decoder_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.975831100Z",
     "start_time": "2025-03-10T16:53:45.810832400Z"
    }
   },
   "id": "71de36a342e167a9",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-10T16:53:45.976830300Z",
     "start_time": "2025-03-10T16:53:45.822330600Z"
    }
   },
   "id": "5cea2fbc17989fbf",
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
