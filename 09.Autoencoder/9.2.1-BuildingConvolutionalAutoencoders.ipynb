{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_shape, \n",
    "                 conv_filters, \n",
    "                 conv_kernels, \n",
    "                 conv_strides, \n",
    "                 latent_space_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.conv_filters = conv_filters\n",
    "        self.conv_kernels = conv_kernels\n",
    "        self.conv_strides = conv_strides\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        \n",
    "        self.num_conv_layers = len(self.conv_filters)\n",
    "        self.shape_before_bottleneck = None\n",
    "        \n",
    "        self.conv_layers = self._build_conv_layers()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_layer = self._build_dense_layer()\n",
    "    \n",
    "    def _build_conv_layers(self):\n",
    "        layers = []\n",
    "        # input shape (C, W, H)\n",
    "        in_channels = self.input_shape[0]\n",
    "        for i in range(self.num_conv_layers):\n",
    "            layers.append((\n",
    "                f'conv{i+1}', \n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=self.conv_filters[i],\n",
    "                              kernel_size=self.conv_kernels[i],\n",
    "                              stride=self.conv_strides[i],\n",
    "                              padding=(self.conv_kernels[i]-1) // 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm2d(self.conv_filters[i])\n",
    "                )\n",
    "            ))\n",
    "            in_channels = self.conv_filters[i]\n",
    "        return nn.Sequential(OrderedDict(layers))\n",
    "        \n",
    "    def _build_dense_layer(self):\n",
    "        dummy_input = torch.zeros(1, *self.input_shape)\n",
    "        conv_out = self.conv_layers(dummy_input)\n",
    "        self.shape_before_bottleneck = conv_out.shape[1:]\n",
    "        flattened_size = conv_out.numel()\n",
    "        return nn.Linear(in_features=flattened_size, \n",
    "                         out_features=self.latent_space_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.dense_layer(self.flatten(self.conv_layers(x)))\n",
    "    \n",
    "    def summary(self):\n",
    "        return print(self)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70eed15a9ef65a25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
